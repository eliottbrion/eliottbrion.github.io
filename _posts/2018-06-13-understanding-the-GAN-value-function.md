---
layout: default
title:  "Understanding the GAN value function"
author: "Chester"
---

I recently gained interest for Generative Adversarial Networks. Fascinated by both the theoritical idea and the various applications, I began the lecture of the orginal paper of Goodfellow et al. My enthousiams came down as I got stuch at the first equation. This equation describes the minimax problem that a GAN solves:

$$ \min_G \max_D V(D,G) = \mathbb E_{x \sim p_{data}(x)} [\log D(x)] + \mathbb E _{z \sim p_z (z)} [ \log(1-D(G(z))]$$ 

Despite my search on the web, I haven't found an explanation both convicing and simple. In this article, I propose to share an explanation that I finally found.

Let suppose you have samples $\{(x_i, y_i) \}_ {i=1}^n $ of images $x$ with their corresponding label ($y_i=1$ if $x_i$ has been drawn from $p_data$ and $y_i=0$ if $x_i$ has been drawn from $p_g$. Let's suppose that the labels have been generated by a distribution $D*(x) = P(Y=y | x)$. Our goal is to find this distribution $D*$. Among all possible $D$, the one that generated the samples that we observe with the highest probability:

$$D = \arg \max_D \prod_{i=1}^m P(y-y^{(i)}$$
